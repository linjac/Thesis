CNN1d_UNET_BATCHED0_L1
Optimizer: torch.optim.Adam(cnn_model.parameters(), lr=0.0005)
Loss: nn.L1Loss()
Epochs: 99999
Notes: similar to CNN1d_UNET41_L1
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
CNN1D_UNET                               --
├─Downsample_block: 1-1                  --
│    └─Conv1d: 2-1                       544
│    └─BatchNorm1d: 2-2                  64
│    └─LeakyReLU: 2-3                    --
│    └─Identity: 2-4                     --
│    └─Conv1d: 2-5                       3,104
├─Downsample_block: 1-2                  --
│    └─Conv1d: 2-6                       16,512
│    └─BatchNorm1d: 2-7                  256
│    └─LeakyReLU: 2-8                    --
│    └─Identity: 2-9                     --
│    └─Conv1d: 2-10                      49,280
├─Downsample_block: 1-3                  --
│    └─Conv1d: 2-11                      130,302
│    └─BatchNorm1d: 2-12                 508
│    └─LeakyReLU: 2-13                   --
│    └─Identity: 2-14                    --
│    └─Conv1d: 2-15                      193,802
├─Downsample_block: 1-4                  --
│    └─Conv1d: 2-16                      258,318
│    └─BatchNorm1d: 2-17                 508
│    └─LeakyReLU: 2-18                   --
│    └─Identity: 2-19                    --
│    └─Conv1d: 2-20                      193,802
├─Conv1d: 1-5                            193,802
├─Upsample_block: 1-6                    --
│    └─ConvTranspose1d: 2-21             193,802
│    └─BatchNorm1d: 2-22                 508
│    └─Conv1d: 2-23                      193,802
├─Upsample_block: 1-7                    --
│    └─ConvTranspose1d: 2-24             193,802
│    └─BatchNorm1d: 2-25                 508
│    └─Conv1d: 2-26                      97,664
├─Upsample_block: 1-8                    --
│    └─ConvTranspose1d: 2-27             49,280
│    └─BatchNorm1d: 2-28                 256
│    └─Conv1d: 2-29                      12,320
├─Upsample_block: 1-9                    --
│    └─ConvTranspose1d: 2-30             3,104
│    └─BatchNorm1d: 2-31                 64
│    └─Conv1d: 2-32                      3,104
├─Sequential: 1-10                       --
│    └─Linear: 2-33                      979,047
│    └─ReLU: 2-34                        --
│    └─ConvTranspose1d: 2-35             16,416
│    └─BatchNorm1d: 2-36                 64
│    └─Conv1d: 2-37                      3,104
│    └─ReLU: 2-38                        --
│    └─ConvTranspose1d: 2-39             8,224
│    └─BatchNorm1d: 2-40                 64
│    └─Conv1d: 2-41                      3,104
│    └─ReLU: 2-42                        --
│    └─ConvTranspose1d: 2-43             8,224
│    └─BatchNorm1d: 2-44                 64
│    └─Conv1d: 2-45                      3,104
│    └─ReLU: 2-46                        --
│    └─ConvTranspose1d: 2-47             4,128
│    └─BatchNorm1d: 2-48                 64
│    └─Conv1d: 2-49                      3,104
│    └─ReLU: 2-50                        --
│    └─ConvTranspose1d: 2-51             4,128
│    └─BatchNorm1d: 2-52                 64
│    └─Conv1d: 2-53                      97
=================================================================
Total params: 2,822,016
Trainable params: 2,822,016
Non-trainable params: 0
=================================================================
class CNN1D_UNET(nn.Module):
    def __init__(self, in_channels, out_dim, negative_slope=0.01):
        super(CNN1D_UNET,self).__init__()
        self.out_dim=out_dim
        
        self.downsample1 = Downsample_block(in_channels, 
                                            32, 
                                            kernel_size=[16, 3], 
                                            stride=[4, 3], 
                                            negative_slope=negative_slope)
        self.downsample2 = Downsample_block(32, 
                                            128, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample3 = Downsample_block(128, 
                                            254, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample4 = Downsample_block(254, 
                                            254, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.bottleneckConv = nn.Conv1d(254, 254, 3, stride=1)
        self.upsample1 = Upsample_block(254,
                                        254,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample2 = Upsample_block(254,
                                        128,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample3 = Upsample_block(128,
                                        32,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample4 = Upsample_block(32,
                                        32,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.convTs = nn.Sequential(nn.Linear(1376, 711),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 16, stride=4, padding=1),
                                    nn.BatchNorm1d(32),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 8, stride=4, padding=1),
                                    nn.BatchNorm1d(32),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 8, stride=2, padding=1),
                                    nn.BatchNorm1d(32),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 4, stride=2, padding=1),
                                    nn.BatchNorm1d(32),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 4, stride=1, padding=1),
                                    nn.BatchNorm1d(32),
                                    nn.Conv1d(32, 1, 3)
        )
        
    def forward(self, x, verbose=False):
        """
        Args:
            x of shape (batch_size*IR_len, input_mapped_dim = 4*2*10 = 80): 
            Tensor with transformed input position vectors.
        Returns:
            out of shape (batch_size, 1): value for time step t            
        """
        out, skip1 = self.downsample1(x)
        if verbose: print(out.shape, skip1.shape)
        out, skip2 = self.downsample2(out)
        if verbose: print(out.shape, skip2.shape)
        out, skip3 = self.downsample3(out)
        if verbose: print(out.shape, skip3.shape)
        out, skip4 = self.downsample4(out)
        if verbose: print(out.shape, skip4.shape)
        out = self.bottleneckConv(out)
        if verbose: print(out.shape)
        out = self.upsample1(out, skip4)
        if verbose: print(out.shape)
        out = self.upsample2(out, skip3)
        if verbose: print(out.shape)
        out = self.upsample3(out, skip2)
        if verbose: print(out.shape)
        out = self.upsample4(out, skip1)
        if verbose: print('Last upsample block: ', out.shape)
        out = self.convTs(out)
        if verbose: print(out.shape)
        out = out[:,:,:self.out_dim]
        if verbose: print(out.shape)
        return out

=============================================
class Downsample_block(nn.Module):
    def __init__(self, 
                 in_channels, 
                 out_channels, 
                 kernel_size, 
                 stride,
                 dropout=False, 
                 negative_slope=0.01):
        super(Downsample_block, self).__init__()
        
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size[0], stride=stride[0])
        self.batch_norm = nn.BatchNorm1d(out_channels, eps=1e-7)
        self.nonlin = nn.LeakyReLU(negative_slope)
        if dropout:
            self.drop = nn.Dropout()
        else:
            self.drop = nn.Identity()
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size[1], stride=stride[1])
        
    def forward(self, x):
        out = self.conv1(x)
        skip = self.batch_norm(out)
        out = self.nonlin(skip)
        out = self.drop(out)
        out = self.conv2(out)
        return out, skip

class Upsample_block(nn.Module):
    def __init__(self, 
                 in_channels, 
                 out_channels, 
                 kernel_size, 
                 convT_stride=2,
                 convT_padding=1,
                 crop_skip=True):
        super(Upsample_block, self).__init__()
        
        self.convT1 = nn.ConvTranspose1d(in_channels, in_channels, kernel_size[0], stride=convT_stride, padding=convT_padding)
        self.batch_norm = nn.BatchNorm1d(in_channels, eps=1e-7)
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size[0])
        self.crop_skip = crop_skip
        
    def forward(self, x, skip):
        out = self.convT1(x)
        out = self.batch_norm(out)
        if self.crop_skip:
            out = torch.concat((out, skip[:,:,out.shape[-1]:]),dim=-1)
        else:
            out = torch.concat((out, skip),dim=-1)
        out = self.conv1(out)
        return out
