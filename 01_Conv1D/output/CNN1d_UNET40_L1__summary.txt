CNN1d_UNET40_L1
Optimizer: torch.optim.Adam(cnn_model.parameters(), lr=0.0005)
Loss: nn.L1Loss()
Epochs: 99999
Notes: The skip connection has been corrected.
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
CNN1D_UNET                               --
├─Downsample_block: 1-1                  --
│    └─Conv1d: 2-1                       1,088
│    └─LeakyReLU: 2-2                    --
│    └─Identity: 2-3                     --
│    └─Conv1d: 2-4                       12,352
├─Downsample_block: 1-2                  --
│    └─Conv1d: 2-5                       16,448
│    └─LeakyReLU: 2-6                    --
│    └─Identity: 2-7                     --
│    └─Conv1d: 2-8                       12,352
├─Downsample_block: 1-3                  --
│    └─Conv1d: 2-9                       32,896
│    └─LeakyReLU: 2-10                   --
│    └─Identity: 2-11                    --
│    └─Conv1d: 2-12                      49,280
├─Downsample_block: 1-4                  --
│    └─Conv1d: 2-13                      65,664
│    └─LeakyReLU: 2-14                   --
│    └─Identity: 2-15                    --
│    └─Conv1d: 2-16                      49,280
├─Conv1d: 1-5                            49,280
├─Upsample_block: 1-6                    --
│    └─ConvTranspose1d: 2-17             196,736
│    └─Conv1d: 2-18                      98,432
├─Upsample_block: 1-7                    --
│    └─ConvTranspose1d: 2-19             196,736
│    └─Conv1d: 2-20                      49,216
├─Upsample_block: 1-8                    --
│    └─ConvTranspose1d: 2-21             65,600
│    └─Conv1d: 2-22                      24,640
├─Upsample_block: 1-9                    --
│    └─ConvTranspose1d: 2-23             65,600
│    └─Conv1d: 2-24                      24,640
├─Sequential: 1-10                       --
│    └─ConvTranspose1d: 2-25             65,600
│    └─Conv1d: 2-26                      12,352
│    └─ReLU: 2-27                        --
│    └─ConvTranspose1d: 2-28             32,832
│    └─Conv1d: 2-29                      12,352
│    └─ReLU: 2-30                        --
│    └─ConvTranspose1d: 2-31             32,832
│    └─Conv1d: 2-32                      12,352
│    └─ReLU: 2-33                        --
│    └─ConvTranspose1d: 2-34             16,448
│    └─Conv1d: 2-35                      12,352
│    └─ReLU: 2-36                        --
│    └─ConvTranspose1d: 2-37             16,448
│    └─Conv1d: 2-38                      193
=================================================================
Total params: 1,224,001
Trainable params: 1,224,001
Non-trainable params: 0
=================================================================

class CNN1D_UNET(nn.Module):
    def __init__(self, in_channels, out_dim, negative_slope=0.01, base_channels=64):
        super(CNN1D_UNET,self).__init__()
        self.out_dim=out_dim
        
        self.downsample1 = Downsample_block(in_channels, 
                                            base_channels, 
                                            kernel_size=[16, 3], 
                                            stride=[4, 3], 
                                            negative_slope=negative_slope)
        self.downsample2 = Downsample_block(base_channels, 
                                            base_channels, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample3 = Downsample_block(base_channels, 
                                            2*base_channels, 
                                            kernel_size=[4, 3], 
                                             stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample4 = Downsample_block(2*base_channels, 
                                            2*base_channels, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.bottleneckConv = nn.Conv1d(2*base_channels, 2*base_channels, 3, stride=1)
        self.upsample1 = Upsample_block(2*base_channels,
                                        2*base_channels,
                                        kernel_size=[12, 3],
                                        stride=[3,1],
                                        padding=[1,0],
                                        crop_skip=True)
        self.upsample2 = Upsample_block(2*base_channels,
                                        base_channels,
                                        kernel_size=[12, 3],
                                        stride=[3,1],
                                        padding=[1,1],
                                        crop_skip=True)
        self.upsample3 = Upsample_block(base_channels,
                                        base_channels,
                                        kernel_size=[16, 3],
                                        stride=[3,1],
                                        padding=[1,1],
                                        crop_skip=True)
        self.upsample4 = Upsample_block(base_channels,
                                        64,
                                        kernel_size=[16, 3],
                                        stride=[3,1],
                                        padding=[1,1],
                                        crop_skip=True)
        self.convTs = nn.Sequential(#nn.Linear(595, 711, bias=False),
                                    #nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 16, stride=4, padding=1),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 8, stride=4, padding=1),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 8, stride=3, padding=1),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 4, stride=2, padding=1),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 4, stride=1, padding=1),
                                    nn.Conv1d(64, 1, 3)
        )
        
    def forward(self, x, verbose=False):
        """
        Args:
            x of shape (batch_size*IR_len, input_mapped_dim = 4*2*10 = 80): 
            Tensor with transformed input position vectors.
        Returns:
            out of shape (batch_size, 1): value for time step t            
        """
        out, skip1 = self.downsample1(x)
        if verbose: print(out.shape, skip1.shape)
        out, skip2 = self.downsample2(out)
        if verbose: print(out.shape, skip2.shape)
        out, skip3 = self.downsample3(out)
        if verbose: print(out.shape, skip3.shape)
        out, skip4 = self.downsample4(out)
        if verbose: print(out.shape, skip4.shape)
        out = self.bottleneckConv(out)
        if verbose: print('Bottleneck: ', out.shape)
        out = self.upsample1(out, skip4, verbose)
        if verbose: print(out.shape)
        out = self.upsample2(out, skip3, verbose)
        if verbose: print(out.shape)
        out = self.upsample3(out, skip2, verbose)
        if verbose: print(out.shape)
        out = self.upsample4(out, skip1, verbose)
        if verbose: print('Last upsample block: ', out.shape)
        out = self.convTs(out)
        if verbose: print(out.shape)
        out = out[:,:,:self.out_dim]
        if verbose: print(out.shape)
        return out

============================================
class Downsample_block(nn.Module):
    def __init__(self, 
                 in_channels, 
                 out_channels, 
                 kernel_size, 
                 stride,
                 dropout=False, 
                 negative_slope=0.01):
        super(Downsample_block, self).__init__()
        
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size[0], stride=stride[0])
        self.nonlin = nn.LeakyReLU(negative_slope)
        if dropout:
            self.drop = nn.Dropout()
        else:
            self.drop = nn.Identity()
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size[1], stride=stride[1])
        
    def forward(self, x):
        skip = self.conv1(x)
        out = self.nonlin(skip)
        out = self.drop(out)
        out = self.conv2(out)
        return out, skip

class Upsample_block(nn.Module):
    def __init__(self, 
                 in_channels, 
                 out_channels, 
                 kernel_size, 
                 stride=[2,1],
                 padding=[1,1],
                 crop_skip=True):
        super(Upsample_block, self).__init__()
        
        self.convT1 = nn.ConvTranspose1d(in_channels, in_channels, kernel_size[0], stride=stride[0], padding=padding[0])
        self.conv1 = nn.Conv1d(2*in_channels, out_channels, kernel_size[1], stride=stride[1], padding=padding[1])
        self.crop_skip = crop_skip
        
    def forward(self, x, skip, verbose=False):
        out = self.convT1(x)
        if verbose: print('Upsample block: ', out.shape)
        if self.crop_skip:
            out = torch.concat((out, skip[:,:,-out.shape[-1]:]),dim=1)
        else:
            out = torch.concat((out, skip),dim=1)
        if verbose: print(out.shape)
        out = self.conv1(out)
        return out