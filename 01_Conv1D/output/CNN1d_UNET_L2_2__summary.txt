CNN1d_UNET_L2_2
Optimizer: torch.optim.Adam(cnn_model.parameters(), lr=0.0005)
Loss: nn.MSELoss()
Epochs: 99999
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
CNN1D_UNET                               --
├─Downsample_block: 1-1                  --
│    └─Conv1d: 2-1                       544
│    └─LeakyReLU: 2-2                    --
│    └─Identity: 2-3                     --
│    └─Conv1d: 2-4                       3,104
├─Downsample_block: 1-2                  --
│    └─Conv1d: 2-5                       16,512
│    └─LeakyReLU: 2-6                    --
│    └─Identity: 2-7                     --
│    └─Conv1d: 2-8                       49,280
├─Downsample_block: 1-3                  --
│    └─Conv1d: 2-9                       130,302
│    └─LeakyReLU: 2-10                   --
│    └─Identity: 2-11                    --
│    └─Conv1d: 2-12                      193,802
├─Conv1d: 1-4                            193,802
├─Upsample_block: 1-5                    --
│    └─ConvTranspose1d: 2-13             193,802
│    └─Conv1d: 2-14                      97,664
├─Upsample_block: 1-6                    --
│    └─ConvTranspose1d: 2-15             49,280
│    └─Conv1d: 2-16                      12,320
├─Upsample_block: 1-7                    --
│    └─ConvTranspose1d: 2-17             3,104
│    └─Conv1d: 2-18                      3,104
├─Sequential: 1-8                        --
│    └─ConvTranspose1d: 2-19             16,416
│    └─Conv1d: 2-20                      3,104
│    └─ConvTranspose1d: 2-21             8,224
│    └─Conv1d: 2-22                      3,104
│    └─ConvTranspose1d: 2-23             8,224
│    └─Conv1d: 2-24                      3,104
│    └─ConvTranspose1d: 2-25             4,128
│    └─Conv1d: 2-26                      3,104
│    └─ConvTranspose1d: 2-27             4,128
│    └─Conv1d: 2-28                      97
=================================================================
Total params: 1,000,253
Trainable params: 1,000,253
Non-trainable params: 0
=================================================================

class CNN1D_UNET(nn.Module):
    def __init__(self, in_channels, out_dim, negative_slope=0.01):
        super(CNN1D_UNET,self).__init__()
        self.out_dim=out_dim
        
        self.downsample1 = Downsample_block(in_channels, 
                                            32, 
                                            kernel_size=[16, 3], 
                                            stride=[4, 3], 
                                            negative_slope=negative_slope)
        self.downsample2 = Downsample_block(32, 
                                            128, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample3 = Downsample_block(128, 
                                            254, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.bottleneckConv = nn.Conv1d(254, 254, 3, stride=1)
        self.upsample1 = Upsample_block(254,
                                        128,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample2 = Upsample_block(128,
                                        32,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample3 = Upsample_block(32,
                                        32,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=True)
        self.convTs = nn.Sequential(nn.ConvTranspose1d(32, 32, 16, stride=4, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ConvTranspose1d(32, 32, 8, stride=4, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ConvTranspose1d(32, 32, 8, stride=2, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ConvTranspose1d(32, 32, 4, stride=2, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ConvTranspose1d(32, 32, 4, stride=1, padding=1),
                                    nn.Conv1d(32, 1, 3)
        )
        
    def forward(self, x):
        """
        Args:
            x of shape (batch_size*IR_len, input_mapped_dim = 4*2*10 = 80): 
            Tensor with transformed input position vectors.
        Returns:
            out of shape (batch_size, 1): value for time step t            
        """
        out, skip1 = self.downsample1(x)
#         print(skip1.shape)
        out, skip2 = self.downsample2(out)
        out, skip3 = self.downsample3(out)
#         print(out.shape)
        out = self.bottleneckConv(out)
#         print(out.shape)
        out = self.upsample1(out, skip3)
#         print(out.shape)
        out = self.upsample2(out, skip2)
#         print(out.shape)
        out = self.upsample3(out, skip1)
#         print(out.shape)
        out = self.convTs(out)
#         print(out.shape)
        out = out[:,:,:self.out_dim]
#         print(out.shape)
        return out