CNN1d_UNET41_L1
Optimizer: torch.optim.Adam(cnn_model.parameters(), lr=0.0005)
Loss: nn.L1Loss()
Epochs: 99999
Notable changes: skip connections are not cropped. Resulting UNet output shape increases -- so the linear layer increases size.
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
CNN1D_UNET                               --
├─Downsample_block: 1-1                  --
│    └─Conv1d: 2-1                       544
│    └─LeakyReLU: 2-2                    --
│    └─Identity: 2-3                     --
│    └─Conv1d: 2-4                       3,104
├─Downsample_block: 1-2                  --
│    └─Conv1d: 2-5                       16,512
│    └─LeakyReLU: 2-6                    --
│    └─Identity: 2-7                     --
│    └─Conv1d: 2-8                       49,280
├─Downsample_block: 1-3                  --
│    └─Conv1d: 2-9                       130,302
│    └─LeakyReLU: 2-10                   --
│    └─Identity: 2-11                    --
│    └─Conv1d: 2-12                      193,802
├─Downsample_block: 1-4                  --
│    └─Conv1d: 2-13                      258,318
│    └─LeakyReLU: 2-14                   --
│    └─Identity: 2-15                    --
│    └─Conv1d: 2-16                      193,802
├─Conv1d: 1-5                            193,802
├─Upsample_block: 1-6                    --
│    └─ConvTranspose1d: 2-17             193,802
│    └─Conv1d: 2-18                      193,802
├─Upsample_block: 1-7                    --
│    └─ConvTranspose1d: 2-19             193,802
│    └─Conv1d: 2-20                      97,664
├─Upsample_block: 1-8                    --
│    └─ConvTranspose1d: 2-21             49,280
│    └─Conv1d: 2-22                      12,320
├─Upsample_block: 1-9                    --
│    └─ConvTranspose1d: 2-23             3,104
│    └─Conv1d: 2-24                      3,104
├─Sequential: 1-10                       --
│    └─Linear: 2-25                      978,336
│    └─ReLU: 2-26                        --
│    └─ConvTranspose1d: 2-27             16,416
│    └─Conv1d: 2-28                      3,104
│    └─ReLU: 2-29                        --
│    └─ConvTranspose1d: 2-30             8,224
│    └─Conv1d: 2-31                      3,104
│    └─ReLU: 2-32                        --
│    └─ConvTranspose1d: 2-33             8,224
│    └─Conv1d: 2-34                      3,104
│    └─ReLU: 2-35                        --
│    └─ConvTranspose1d: 2-36             4,128
│    └─Conv1d: 2-37                      3,104
│    └─ReLU: 2-38                        --
│    └─ConvTranspose1d: 2-39             4,128
│    └─Conv1d: 2-40                      97
=================================================================
Total params: 2,818,313
Trainable params: 2,818,313
Non-trainable params: 0
=================================================================
class CNN1D_UNET(nn.Module):
    def __init__(self, in_channels, out_dim, negative_slope=0.01):
        super(CNN1D_UNET,self).__init__()
        self.out_dim=out_dim
        
        self.downsample1 = Downsample_block(in_channels, 
                                            32, 
                                            kernel_size=[16, 3], 
                                            stride=[4, 3], 
                                            negative_slope=negative_slope)
        self.downsample2 = Downsample_block(32, 
                                            128, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample3 = Downsample_block(128, 
                                            254, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample4 = Downsample_block(254, 
                                            254, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.bottleneckConv = nn.Conv1d(254, 254, 3, stride=1)
        self.upsample1 = Upsample_block(254,
                                        254,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample2 = Upsample_block(254,
                                        128,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample3 = Upsample_block(128,
                                        32,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.upsample4 = Upsample_block(32,
                                        32,
                                        kernel_size=[3, 3],
                                        convT_stride=2,
                                        convT_padding=1,
                                        crop_skip=False)
        self.convTs = nn.Sequential(nn.Linear(1376, 711, bias=False),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 16, stride=4, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 8, stride=4, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 8, stride=2, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 4, stride=2, padding=1),
                                    nn.Conv1d(32, 32, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(32, 32, 4, stride=1, padding=1),
                                    nn.Conv1d(32, 1, 3)
        )
        
    def forward(self, x, verbose=False):
        """
        Args:
            x of shape (batch_size*IR_len, input_mapped_dim = 4*2*10 = 80): 
            Tensor with transformed input position vectors.
        Returns:
            out of shape (batch_size, 1): value for time step t            
        """
        out, skip1 = self.downsample1(x)
        if verbose: print(out.shape, skip1.shape)
        out, skip2 = self.downsample2(out)
        if verbose: print(out.shape, skip2.shape)
        out, skip3 = self.downsample3(out)
        if verbose: print(out.shape, skip3.shape)
        out, skip4 = self.downsample4(out)
        if verbose: print(out.shape, skip4.shape)
        out = self.bottleneckConv(out)
        if verbose: print(out.shape)
        out = self.upsample1(out, skip4)
        if verbose: print(out.shape)
        out = self.upsample2(out, skip3)
        if verbose: print(out.shape)
        out = self.upsample3(out, skip2)
        if verbose: print(out.shape)
        out = self.upsample4(out, skip1)
        if verbose: print('Last upsample block: ', out.shape)
        out = self.convTs(out)
        if verbose: print(out.shape)
        out = out[:,:,:self.out_dim]
        if verbose: print(out.shape)
        return out