CNN1d_UNET40_BATCHED_L1
Optimizer: torch.optim.Adam(cnn_model.parameters(), lr=0.0005)
Loss: nn.L1Loss()
Epochs: 99999
Notes: The skip connection has been corrected. This is the batched version with batchnorm
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
CNN1D_UNET                               --
├─Downsample_block: 1-1                  --
│    └─Conv1d: 2-1                       1,088
│    └─BatchNorm1d: 2-2                  128
│    └─LeakyReLU: 2-3                    --
│    └─Identity: 2-4                     --
│    └─Conv1d: 2-5                       12,352
├─Downsample_block: 1-2                  --
│    └─Conv1d: 2-6                       16,448
│    └─BatchNorm1d: 2-7                  128
│    └─LeakyReLU: 2-8                    --
│    └─Identity: 2-9                     --
│    └─Conv1d: 2-10                      12,352
├─Downsample_block: 1-3                  --
│    └─Conv1d: 2-11                      32,896
│    └─BatchNorm1d: 2-12                 256
│    └─LeakyReLU: 2-13                   --
│    └─Identity: 2-14                    --
│    └─Conv1d: 2-15                      49,280
├─Downsample_block: 1-4                  --
│    └─Conv1d: 2-16                      65,664
│    └─BatchNorm1d: 2-17                 256
│    └─LeakyReLU: 2-18                   --
│    └─Identity: 2-19                    --
│    └─Conv1d: 2-20                      49,280
├─Conv1d: 1-5                            49,280
├─Upsample_block: 1-6                    --
│    └─ConvTranspose1d: 2-21             196,736
│    └─BatchNorm1d: 2-22                 256
│    └─Conv1d: 2-23                      98,432
├─Upsample_block: 1-7                    --
│    └─ConvTranspose1d: 2-24             196,736
│    └─BatchNorm1d: 2-25                 256
│    └─Conv1d: 2-26                      49,216
├─Upsample_block: 1-8                    --
│    └─ConvTranspose1d: 2-27             65,600
│    └─BatchNorm1d: 2-28                 128
│    └─Conv1d: 2-29                      24,640
├─Upsample_block: 1-9                    --
│    └─ConvTranspose1d: 2-30             65,600
│    └─BatchNorm1d: 2-31                 128
│    └─Conv1d: 2-32                      24,640
├─Sequential: 1-10                       --
│    └─ConvTranspose1d: 2-33             65,600
│    └─BatchNorm1d: 2-34                 128
│    └─Conv1d: 2-35                      12,352
│    └─ReLU: 2-36                        --
│    └─ConvTranspose1d: 2-37             32,832
│    └─BatchNorm1d: 2-38                 128
│    └─Conv1d: 2-39                      12,352
│    └─ReLU: 2-40                        --
│    └─ConvTranspose1d: 2-41             32,832
│    └─BatchNorm1d: 2-42                 128
│    └─Conv1d: 2-43                      12,352
│    └─ReLU: 2-44                        --
│    └─ConvTranspose1d: 2-45             16,448
│    └─BatchNorm1d: 2-46                 128
│    └─Conv1d: 2-47                      12,352
│    └─ReLU: 2-48                        --
│    └─ConvTranspose1d: 2-49             16,448
│    └─Conv1d: 2-50                      193
=================================================================
Total params: 1,226,049
Trainable params: 1,226,049
Non-trainable params: 0
=================================================================
class CNN1D_UNET(nn.Module):
    def __init__(self, in_channels, out_dim, negative_slope=0.01, base_channels=64):
        super(CNN1D_UNET,self).__init__()
        self.out_dim=out_dim
        
        self.downsample1 = Downsample_block(in_channels, 
                                            base_channels, 
                                            kernel_size=[16, 3], 
                                            stride=[4, 3], 
                                            negative_slope=negative_slope)
        self.downsample2 = Downsample_block(base_channels, 
                                            base_channels, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample3 = Downsample_block(base_channels, 
                                            2*base_channels, 
                                            kernel_size=[4, 3], 
                                             stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.downsample4 = Downsample_block(2*base_channels, 
                                            2*base_channels, 
                                            kernel_size=[4, 3], 
                                            stride=[1, 3], 
                                            negative_slope=negative_slope)
        self.bottleneckConv = nn.Conv1d(2*base_channels, 2*base_channels, 3, stride=1)
        self.upsample1 = Upsample_block(2*base_channels,
                                        2*base_channels,
                                        kernel_size=[12, 3],
                                        stride=[3,1],
                                        padding=[1,0],)
        self.upsample2 = Upsample_block(2*base_channels,
                                        base_channels,
                                        kernel_size=[12, 3],
                                        stride=[3,1],
                                        padding=[1,1])
        self.upsample3 = Upsample_block(base_channels,
                                        base_channels,
                                        kernel_size=[16, 3],
                                        stride=[3,1],
                                        padding=[1,1])
        self.upsample4 = Upsample_block(base_channels,
                                        64,
                                        kernel_size=[16, 3],
                                        stride=[3,1],
                                        padding=[1,1])
        self.convTs = nn.Sequential(
                                    nn.ConvTranspose1d(64, 64, 16, stride=4, padding=1),
                                    nn.BatchNorm1d(64),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 8, stride=4, padding=1),
                                    nn.BatchNorm1d(64),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 8, stride=3, padding=1),
                                    nn.BatchNorm1d(64),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 4, stride=2, padding=1),
                                    nn.BatchNorm1d(64),
                                    nn.Conv1d(64, 64, 3),
                                    nn.ReLU(),
                                    nn.ConvTranspose1d(64, 64, 4, stride=1, padding=1),
                                    nn.Conv1d(64, 1, 3)
        )
        
    def forward(self, x, verbose=False):
        """
        Args:
            x of shape (batch_size*IR_len, input_mapped_dim = 4*2*10 = 80): 
            Tensor with transformed input position vectors.
        Returns:
            out of shape (batch_size, 1): value for time step t            
        """
        out, skip1 = self.downsample1(x)
        if verbose: print(out.shape, skip1.shape)
        out, skip2 = self.downsample2(out)
        if verbose: print(out.shape, skip2.shape)
        out, skip3 = self.downsample3(out)
        if verbose: print(out.shape, skip3.shape)
        out, skip4 = self.downsample4(out)
        if verbose: print(out.shape, skip4.shape)
        out = self.bottleneckConv(out)
        if verbose: print('Bottleneck: ', out.shape)
        out = self.upsample1(out, skip4, verbose)
        if verbose: print(out.shape)
        out = self.upsample2(out, skip3, verbose)
        if verbose: print(out.shape)
        out = self.upsample3(out, skip2, verbose)
        if verbose: print(out.shape)
        out = self.upsample4(out, skip1, verbose)
        if verbose: print('Last upsample block: ', out.shape)
        out = self.convTs(out)
        if verbose: print(out.shape)
        out = out[:,:,:self.out_dim]
        if verbose: print(out.shape)
        return out

============================================
class Downsample_block(nn.Module):
    def __init__(self, 
                 in_channels, 
                 out_channels, 
                 kernel_size, 
                 stride,
                 dropout=False, 
                 negative_slope=0.01):
        super(Downsample_block, self).__init__()
        
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size[0], stride=stride[0])
        self.batch_norm = nn.BatchNorm1d(out_channels, eps=1e-7)
        self.nonlin = nn.LeakyReLU(negative_slope)
        if dropout:
            self.drop = nn.Dropout()
        else:
            self.drop = nn.Identity()
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size[1], stride=stride[1])
        
    def forward(self, x):
        out = self.conv1(x)
        skip = self.batch_norm(out)
        out = self.nonlin(skip)
        out = self.drop(out)
        out = self.conv2(out)
        return out, skip

class Upsample_block(nn.Module):
    def __init__(self, 
                 in_channels, 
                 out_channels, 
                 kernel_size, 
                 stride=[2,1],
                 padding=[1,1]):
        super(Upsample_block, self).__init__()
        
        self.convT1 = nn.ConvTranspose1d(in_channels, in_channels, kernel_size[0], stride=stride[0], padding=padding[0])
        self.batch_norm = nn.BatchNorm1d(in_channels, eps=1e-7)
        self.conv1 = nn.Conv1d(2*in_channels, out_channels, kernel_size[1], stride=stride[1], padding=padding[1])
        
    def forward(self, x, skip, verbose=False):
        out = self.convT1(x)
        out = self.batch_norm(out)
        if verbose: print('Upsample block: ', out.shape)
        out = torch.concat((out, skip[:,:,-out.shape[-1]:]),dim=1)
        if verbose: print('                ', out.shape)
        out = self.conv1(out)
        return out