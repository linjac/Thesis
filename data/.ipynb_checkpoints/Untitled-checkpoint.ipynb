{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1effbe7a",
   "metadata": {},
   "source": [
    "# Pyroomacoustics - Generate IR dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "normalizer = preprocessing.Normalizer()\n",
    "normalized_train_x = normalizer.fit_transform(x_train)\n",
    "normalized_test_x = normalizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaff847",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example program demonstrates the use of ray tracing\n",
    "for the simulation of rooms of different sizes.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import pyroomacoustics as pra\n",
    "\n",
    "fs, audio_anechoic = wavfile.read(\"notebooks/arctic_a0010.wav\")\n",
    "\n",
    "reverb_opts = {\n",
    "    \"medium\": {\"e_abs\": 0.3},\n",
    "    \"short\": {\n",
    "        \"e_abs\": 0.7,\n",
    "    },\n",
    "    \"long\": {\"e_abs\": 0.1},\n",
    "}\n",
    "\n",
    "size_opts = {\n",
    "    \"medium\": {\"mult\": 2.5, \"receiver_radius\": 0.2},\n",
    "    \"large\": {\"mult\": 5.0, \"receiver_radius\": 0.5},\n",
    "    \"small\": {\"mult\": 1.0, \"receiver_radius\": 0.1},\n",
    "}\n",
    "\n",
    "\n",
    "def get_rir(size, reverb):\n",
    "    # We construct a non-shoebox room\n",
    "    pol = size_opts[size][\"mult\"] * np.array([[0, 0], [0, 4], [3, 2], [3, 0]]).T\n",
    "    mat = pra.Material(reverb_opts[reverb][\"e_abs\"])\n",
    "    room = pra.Room.from_corners(\n",
    "        pol, fs=16000, max_order=2, materials=mat, ray_tracing=True\n",
    "    )\n",
    "\n",
    "    # Create the 3D room by extruding the 2D by a specific height\n",
    "    room.extrude(size_opts[size][\"mult\"] * 2.5, materials=mat)\n",
    "\n",
    "    # set the ray tracing parameters\n",
    "    room.set_ray_tracing(\n",
    "        receiver_radius=size_opts[size][\"receiver_radius\"]\n",
    "    )  # , n_rays=100000)\n",
    "\n",
    "    # Adding the source\n",
    "    room.add_source(\n",
    "        size_opts[size][\"mult\"] * np.array([1.8, 0.4, 1.6]), signal=audio_anechoic\n",
    "    )\n",
    "\n",
    "    # Adding the microphone\n",
    "    R = size_opts[size][\"mult\"] * np.array([[0.5], [1.2], [0.5]])\n",
    "    room.add_microphone_array(pra.MicrophoneArray(R, room.fs))\n",
    "\n",
    "    # Compute the RIR using the hybrid method\n",
    "    s = time.perf_counter()\n",
    "    room.compute_rir()\n",
    "    print(\"Computation time:\", time.perf_counter() - s)\n",
    "\n",
    "    return room.rir[0][0], room\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=(\n",
    "            \"Demonstrates the use of ray tracing for rooms of \"\n",
    "            \"different size and reverberation time\"\n",
    "        )\n",
    "    )\n",
    "    size_choices = list(size_opts.keys())\n",
    "    reverb_choices = list(reverb_opts.keys())\n",
    "    parser.add_argument(\n",
    "        \"size\", choices=size_choices, default=size_choices[0], help=\"room size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"reverb\",\n",
    "        choices=reverb_choices,\n",
    "        default=reverb_choices[0],\n",
    "        help=\"amount of reverberation\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    rir, room = get_rir(size=args.size, reverb=args.reverb)\n",
    "\n",
    "    room.plot(img_order=0)\n",
    "    plt.title(\"The room we have simulated\")\n",
    "\n",
    "    # Plot and apply the RIR on the audio file\n",
    "    plt.figure()\n",
    "    room.plot_rir()\n",
    "    plt.show()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # print('Max error (rel):', np.max(np.abs(new_rir - old_rir))/np.max(np.abs(new_rir)))\n",
    "    # print('Mean error (rel):', np.mean(np.abs(new_rir - old_rir))/np.max(np.abs(new_rir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129788d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this example, we construct an L-shape 3D room. We use the same floor as in\n",
    "the 2D example and extrude a 3D room from the floor with a given height.  This\n",
    "is a simple way to create 3D rooms that fits most situations.  Then, we place\n",
    "one source and two microphones in the room and compute the room impulse\n",
    "responses.\n",
    "\n",
    "The simulation is done using the hybrid ISM/RT simulator.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import pyroomacoustics as pra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97cb45f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'examples/input_samples/cmu_arctic_us_aew_a0001.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m room\u001b[38;5;241m.\u001b[39mset_ray_tracing(receiver_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# # Add a source somewhere in the room\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m fs, audio_anechoic \u001b[38;5;241m=\u001b[39m \u001b[43mwavfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexamples/input_samples/cmu_arctic_us_aew_a0001.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m room\u001b[38;5;241m.\u001b[39madd_source([\u001b[38;5;241m1.5\u001b[39m, \u001b[38;5;241m1.7\u001b[39m, \u001b[38;5;241m1.6\u001b[39m], signal\u001b[38;5;241m=\u001b[39maudio_anechoic)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Add a microphone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Thesis\\lib\\site-packages\\scipy\\io\\wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m     mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     file_size, is_big_endian \u001b[38;5;241m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'examples/input_samples/cmu_arctic_us_aew_a0001.wav'"
     ]
    }
   ],
   "source": [
    "# Create the 2D L-shaped room from the floor polygon\n",
    "pol = np.array([[0, 0], [0, 10], [7.5, 10], [7.5, 6], [5, 6], [5, 0]]).T\n",
    "r_absor = 0.1\n",
    "mat = pra.Material(0.15, 0.1)\n",
    "room = pra.Room.from_corners(\n",
    "    pol,\n",
    "    fs=16000,\n",
    "    # absorption=r_absor,\n",
    "    materials=mat,\n",
    "    max_order=3,\n",
    "    ray_tracing=True,\n",
    "    air_absorption=True,\n",
    ")\n",
    "\n",
    "# # Create the 3D room by extruding the 2D by 10 meters\n",
    "height = 10.0\n",
    "room.extrude(height, materials=mat)\n",
    "\n",
    "room.set_ray_tracing(receiver_radius=0.5)\n",
    "\n",
    "# # Add a source somewhere in the room\n",
    "fs, audio_anechoic = wavfile.read(\"examples/input_samples/cmu_arctic_us_aew_a0001.wav\")\n",
    "room.add_source([1.5, 1.7, 1.6], signal=audio_anechoic)\n",
    "\n",
    "# Add a microphone\n",
    "room.add_microphone([3.0, 2.25, 0.6])\n",
    "\n",
    "# Use the following function to compute the rir using either 'ism' method, 'rt' method, or 'hybrid' method\n",
    "chrono = time.time()\n",
    "room.compute_rir()\n",
    "print(\"Done in\", time.time() - chrono, \"seconds.\")\n",
    "print(\"RT60:\", room.measure_rt60()[0, 0])\n",
    "\n",
    "room.plot_rir()\n",
    "plt.show()\n",
    "room.simulate()\n",
    "audio_reverb = room.mic_array.to_wav(\"aaa.wav\", norm=True, bitdepth=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6dee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
